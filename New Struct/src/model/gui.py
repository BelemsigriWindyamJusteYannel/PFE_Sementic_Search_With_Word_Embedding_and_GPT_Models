"""
import streamlit as st
from sentence_transformers import SentenceTransformer, util


# Charger le modÃ¨le d'embeddings
model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

# Liste de documents
documents = [
    "Les examens doivent se dÃ©rouler dans le respect des horaires dÃ©finis.",
    "Les Ã©tudiants doivent prÃ©senter leur carte d'Ã©tudiant lors des Ã©valuations.",
    "Tout retard au dÃ©but des Ã©preuves sera sanctionnÃ© par une exclusion. L'usage des tÃ©lÃ©phones",
    "L'usage des tÃ©lÃ©phones portables pendant les Ã©valuations est strictement interdit.",
    "Une note infÃ©rieure Ã  5/20 est considÃ©rÃ©e comme un Ã©chec Ã  l'Ã©valuation."
]

# Fonction pour charger le CSS
def load_css(file_name):
    with open(file_name) as f:
        st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)

# Charger le CSS
load_css("style.css")

# Titre de l'application
st.title("ğŸ“šRÃ¨glement IntÃ©rieur des Ã‰valuations Ã  l'EST")
st.markdown("---")

# Champ de saisie de la requÃªte utilisateur
query = st.text_input("ğŸ” **Entrez votre requÃªte de recherche :**")

# Si une requÃªte est saisie
if query:
    st.markdown("### RÃ©sultat de la recherche:")
    # Calculer l'embedding de la requÃªte
    query_embedding = model.encode(query)

   
    doc_embeddings = model.encode(documents)

     # Calculer la similaritÃ© entre la requÃªte et les documents
    scores = util.cos_sim(query_embedding, doc_embeddings)[0]

    #recuperer l'id de la similaritÃ© le plus  Ã©lÃ©vÃ© en terme de score .
    best_idx = scores.argmax()

    best_score = scores[best_idx].item()
    best_doc = documents[best_idx] #Recuperer la meilleur reponse Ã  travers son id . 

    # Afficher le rÃ©sultat
    st.success(f"{best_doc}")
    #st.info(f"Confiance : {best_score:.4f}")
else:
    st.info("Veuillez entrer une requÃªte dans le champ ci-dessus.")

"""


from model import get_model_response
import streamlit as st

st.title("Renseignement")

# Where we will store questions history
if "messages" not in st.session_state:
    st.session_state.messages = []

# Now were will display our history in the interface
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])


# User input
if prompt:=st.chat_input("what's up?"):
    # Were're going to display user message in the interface
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # We will add the user message to the history
    st.session_state.messages.append({"role":"user","content":prompt})

    response = f"Echo : {get_model_response(prompt)}"
    # We are now about to display the response
    with st.chat_message("assistart"):
        st.markdown(response)
    
    # Finally we will add to the history the response
    st.session_state.messages.append({"role":"assistant","content":response})